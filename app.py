"""
Streamlit ì›¹ ì•±: Rock Pine ìµœì  ìƒìœ¡ í™˜ê²½ ì¶”ì²œ ì‹œìŠ¤í…œ

CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import io
from pathlib import Path
from typing import List, Tuple

import pandas as pd
import streamlit as st
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.metrics import (classification_report, f1_score,
                             mean_absolute_error, mean_squared_error)
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Rock Pine ìµœì  ìƒìœ¡ í™˜ê²½ ì¶”ì²œ",
    page_icon="ğŸŒ²",
    layout="wide",
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "df" not in st.session_state:
    st.session_state.df = None
if "selected_features" not in st.session_state:
    st.session_state.selected_features = []
if "height_target" not in st.session_state:
    st.session_state.height_target = 'ì„±ì¥ë†’ì´' #None
if "health_target" not in st.session_state:
    st.session_state.health_target = 'ê±´ê°•ìƒíƒœ' #None
if "artifacts" not in st.session_state:
    st.session_state.artifacts = None
if "metrics" not in st.session_state:
    st.session_state.metrics = None
if "recommendations" not in st.session_state:
    st.session_state.recommendations = None


def detect_column_types(df: pd.DataFrame, columns: List[str]) -> Tuple[List[str], List[str]]:
    """ì»¬ëŸ¼ì„ categoricalê³¼ numericìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    categorical = []
    numeric = []
    
    for col in columns:
        if col not in df.columns:
            continue
        # ìˆ«ìí˜•ì´ì§€ë§Œ ê³ ìœ ê°’ì´ ì ìœ¼ë©´ categoricalë¡œ ê°„ì£¼
        if df[col].dtype in ["object", "string", "category"]:
            categorical.append(col)
        #elif df[col].nunique() < 3 and df[col].dtype in ["int64", "int32"]:
        # col 'ëª¨ì¢… ì—°ì‹'ì¼ ê²½ìš°  categoricalë¡œ ê°„ì£¼    
        elif col == 'ëª¨ì¢…ì—°ì‹':
            categorical.append(col)
        else:
            numeric.append(col)
    
    return categorical, numeric


def build_preprocessor_dynamic(
    categorical_features: List[str],
    numeric_features: List[str],
) -> ColumnTransformer:
    """ë™ì ìœ¼ë¡œ ì „ì²˜ë¦¬ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    categorical_pipeline = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False)),
        ]
    )

    numeric_pipeline = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="median")),
        ]
    )

    transformers = []
    if categorical_features:
        transformers.append(("cat", categorical_pipeline, categorical_features))
    if numeric_features:
        transformers.append(("num", numeric_pipeline, numeric_features))

    preprocessor = ColumnTransformer(transformers=transformers)
    return preprocessor


def train_models_dynamic(
    df: pd.DataFrame,
    feature_columns: List[str],
    height_target: str,
    health_target: str,
    healthy_label: str = "0",
) -> Tuple[dict, dict]:
    """ë™ì  ì»¬ëŸ¼ ì„ íƒìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."""
    features = df[feature_columns].copy()
    height_targets = df[height_target].astype(float)
    health_targets = df[health_target].astype(str)

    # ë°ì´í„° íƒ€ì… ë¶„ë¥˜
    categorical_features, numeric_features = detect_column_types(features, feature_columns)

    # ì „ì²˜ë¦¬ê¸° ìƒì„±
    preprocessor = build_preprocessor_dynamic(categorical_features, numeric_features)

    # ë°ì´í„° ë¶„í• 
    (
        x_train,
        x_valid,
        height_train,
        height_valid,
        health_train,
        health_valid,
    ) = train_test_split(
        features,
        height_targets,
        health_targets,
        test_size=0.2,
        random_state=42,
        stratify=health_targets,
    )

    # ë†’ì´ ì˜ˆì¸¡ ëª¨ë¸
    height_pipeline = Pipeline(
        steps=[
            ("preprocessor", preprocessor),
            (
                "model",
                RandomForestRegressor(
                    n_estimators=300,
                    random_state=42,
                    min_samples_leaf=2,
                    max_features="sqrt",
                    n_jobs=-1,
                ),
            ),
        ],
    )

    # ê±´ê°• ìƒíƒœ ë¶„ë¥˜ ëª¨ë¸
    health_pipeline = Pipeline(
        steps=[
            ("preprocessor", preprocessor),
            (
                "model",
                RandomForestClassifier(
                    n_estimators=400,
                    random_state=42,
                    class_weight="balanced",
                    min_samples_leaf=2,
                    max_features="sqrt",
                    n_jobs=-1,
                ),
            ),
        ],
    )

    # ëª¨ë¸ í•™ìŠµ
    with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘..."):
        height_pipeline.fit(x_train, height_train)
        health_pipeline.fit(x_train, health_train)

    # ê²€ì¦ í‰ê°€
    height_pred = height_pipeline.predict(x_valid)
    height_mae = mean_absolute_error(height_valid, height_pred)
    height_rmse = mean_squared_error(height_valid, height_pred) #, squared=False)

    health_pred = health_pipeline.predict(x_valid)
    health_f1 = f1_score(
        health_valid == healthy_label,
        health_pred == healthy_label,
        zero_division=0,
    )

    metrics = {
        "height_mae": float(height_mae),
        "height_rmse": float(height_rmse),
        "health_f1": float(health_f1),
        "health_classification_report": classification_report(
            health_valid,
            health_pred,
            digits=3,
            zero_division=0,
        ),
    }

    # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ
    height_pipeline.fit(features, height_targets)
    health_pipeline.fit(features, health_targets)

    artifacts = {
        "height_pipeline": height_pipeline,
        "health_pipeline": health_pipeline,
        "feature_columns": feature_columns,
        "categorical_features": categorical_features,
        "numeric_features": numeric_features,
    }

    return artifacts, metrics


def recommend_environments_dynamic(
    artifacts: dict,
    df: pd.DataFrame,
    height_target: str,
    health_target: str,
    healthy_label: str = "0",
    top_k: int = 5,
) -> pd.DataFrame:
    """ìµœì  í™˜ê²½ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    feature_columns = artifacts["feature_columns"]
    feature_space = df[feature_columns].drop_duplicates().reset_index(drop=True)

    if feature_space.empty:
        return pd.DataFrame()

    expected_height = artifacts["height_pipeline"].predict(feature_space)
    health_proba_all = artifacts["health_pipeline"].predict_proba(feature_space)
    
    try:
        healthy_idx = list(artifacts["health_pipeline"].named_steps["model"].classes_).index(healthy_label)
        healthy_probability = health_proba_all[:, healthy_idx]
    except ValueError:
        # healthy_labelì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í´ë˜ìŠ¤ ì‚¬ìš©
        healthy_probability = health_proba_all[:, 0]

    recommendations = feature_space.copy()
    recommendations["ì˜ˆìƒ ë†’ì´"] = expected_height
    recommendations["ê±´ê°• í™•ë¥ "] = healthy_probability
    recommendations["score"] = (
        recommendations["ì˜ˆìƒ ë†’ì´"] * recommendations["ê±´ê°• í™•ë¥ "]
    )

    recommendations = recommendations.sort_values(
        by=["ê±´ê°• í™•ë¥ ", "ì˜ˆìƒ ë†’ì´", "score"],
        ascending=[False, False, False],
    ).reset_index(drop=True)

    return recommendations.head(top_k)


# ë©”ì¸ UI
st.title("ğŸŒ² Rock Pine ìµœì  ìƒìœ¡ í™˜ê²½ ì¶”ì²œ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ ë° ì„¤ì •
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=["csv"],
        help="í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
    )

    if uploaded_file is not None:
        try:
            # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„ (í•œêµ­ì–´ íŒŒì¼ ì§€ì›)
            encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
            df = None
            last_error = None
            
            for encoding in encodings:
                try:
                    uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë¦¬ì…‹
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    break
                except (UnicodeDecodeError, UnicodeError) as e:
                    last_error = e
                    continue
            
            if df is None:
                raise last_error if last_error else Exception("íŒŒì¼ ì¸ì½”ë”©ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            st.session_state.df = df
            st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} ì»¬ëŸ¼")
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            st.session_state.df = None

    st.divider()

    if st.session_state.df is not None:
        st.header("âš™ï¸ ëª¨ë¸ ì„¤ì •")
        top_k = st.slider("ì¶”ì²œ ê°œìˆ˜", min_value=1, max_value=20, value=5)
        healthy_label = st.text_input("ê±´ê°• ìƒíƒœ ë ˆì´ë¸”", value="ì •ìƒ", help="ì •ìƒ ìƒíƒœë¡œ ê°„ì£¼í•  ë ˆì´ë¸” ê°’")

# ë©”ì¸ ì˜ì—­
if st.session_state.df is None:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²•
    1. ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤
    2. ì…ë ¥ ë³€ìˆ˜(Features)ì™€ íƒ€ê²Ÿ ë³€ìˆ˜(Targets)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤
    3. ëª¨ë¸ í•™ìŠµ ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤
    4. ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤
    """)
else:
    df = st.session_state.df

    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", "ğŸ¯ ì»¬ëŸ¼ ì„ íƒ", "ğŸ¤– ëª¨ë¸ í•™ìŠµ", "ğŸ“ˆ ê²°ê³¼ í™•ì¸"])

    with tab1:
        st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df.head(20), use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì´ í–‰ ìˆ˜", len(df))
        with col2:
            st.metric("ì´ ì»¬ëŸ¼ ìˆ˜", len(df.columns))
        
        st.subheader("ì»¬ëŸ¼ ì •ë³´")
        st.dataframe(
            pd.DataFrame({
                "ì»¬ëŸ¼ëª…": df.columns,
                "ë°ì´í„° íƒ€ì…": df.dtypes.astype(str),
                "ê²°ì¸¡ì¹˜ ìˆ˜": df.isnull().sum(),
                "ê³ ìœ ê°’ ìˆ˜": [df[col].nunique() for col in df.columns],
            }),
            use_container_width=True,
        )

    with tab2:
        st.subheader("í•™ìŠµ ì»¬ëŸ¼ ì„ íƒ")
        
        all_columns = list(df.columns)
        
        # ëª¨ë“  ì»¬ëŸ¼ì„ Categoricalê³¼ Numericìœ¼ë¡œ ë¶„ë¥˜
        categorical_cols, numeric_cols = detect_column_types(df, all_columns)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ì…ë ¥ ë³€ìˆ˜ (Features)")
            
            # ì´ì „ì— ì„ íƒëœ ì»¬ëŸ¼ë“¤
            prev_selected = set(st.session_state.selected_features if st.session_state.selected_features else [])
            
            selected_features = []
            
            # Categorical ì»¬ëŸ¼ ì„¹ì…˜
            if categorical_cols:
                st.markdown("#### ğŸ“‹ Categorical ì»¬ëŸ¼")
                for col in categorical_cols:
                    checked = st.checkbox(
                        f"`{col}`",
                        value=col in prev_selected,
                        key=f"cat_{col}",
                        help=f"íƒ€ì…: {df[col].dtype}, ê³ ìœ ê°’: {df[col].nunique()}ê°œ",
                    )
                    if checked:
                        selected_features.append(col)
            
            # Numeric ì»¬ëŸ¼ ì„¹ì…˜
            if numeric_cols:
                st.markdown("#### ğŸ”¢ Numeric ì»¬ëŸ¼")
                for col in numeric_cols:
                    checked = st.checkbox(
                        f"`{col}`",
                        value=col in prev_selected,
                        key=f"num_{col}",
                        help=f"íƒ€ì…: {df[col].dtype}, ë²”ìœ„: {df[col].min():.2f} ~ {df[col].max():.2f}",
                    )
                    if checked:
                        selected_features.append(col)
            
            st.session_state.selected_features = selected_features
            
            # ì„ íƒ ìš”ì•½
            if selected_features:
                selected_cat, selected_num = detect_column_types(df, selected_features)
                st.info(f"âœ… ì„ íƒë¨: ì´ {len(selected_features)}ê°œ (Categorical: {len(selected_cat)}, Numeric: {len(selected_num)})")
            else:
                st.warning("âš ï¸ ìµœì†Œ 1ê°œ ì´ìƒì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

        with col2:
            st.markdown("### íƒ€ê²Ÿ ë³€ìˆ˜ (Targets)")
            height_target = st.selectbox(
                "ë†’ì´ íƒ€ê²Ÿ ë³€ìˆ˜ (Height)",
                options=all_columns,
                index=all_columns.index(st.session_state.height_target) if st.session_state.height_target in all_columns else 0,
                help="ì˜ˆì¸¡í•  ë†’ì´ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            )
            st.session_state.height_target = height_target

            health_target = st.selectbox(
                "ê±´ê°• ìƒíƒœ íƒ€ê²Ÿ ë³€ìˆ˜ (Health Status)",
                options=all_columns,
                index=all_columns.index(st.session_state.health_target) if st.session_state.health_target in all_columns else 0,
                help="ì˜ˆì¸¡í•  ê±´ê°• ìƒíƒœ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            )
            st.session_state.health_target = health_target

        # ê²€ì¦
        if selected_features and height_target and health_target:
            if height_target in selected_features:
                st.warning("âš ï¸ ë†’ì´ íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ì…ë ¥ ë³€ìˆ˜ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            if health_target in selected_features:
                st.warning("âš ï¸ ê±´ê°• ìƒíƒœ íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ì…ë ¥ ë³€ìˆ˜ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    with tab3:
        st.subheader("ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")
        
        if not st.session_state.selected_features:
            st.warning("âš ï¸ ë¨¼ì € 'ì»¬ëŸ¼ ì„ íƒ' íƒ­ì—ì„œ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        elif not st.session_state.height_target or not st.session_state.health_target:
            st.warning("âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        else:
            if st.button("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
                try:
                    # ë°ì´í„° ê²€ì¦
                    required_cols = (
                        st.session_state.selected_features
                        + [st.session_state.height_target, st.session_state.health_target]
                    )
                    missing_cols = [col for col in required_cols if col not in df.columns]
                    
                    if missing_cols:
                        st.error(f"âŒ ë‹¤ìŒ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
                    else:
                        # ëª¨ë¸ í•™ìŠµ
                        artifacts, metrics = train_models_dynamic(
                            df,
                            st.session_state.selected_features,
                            st.session_state.height_target,
                            st.session_state.health_target,
                            healthy_label,
                        )
                        
                        st.session_state.artifacts = artifacts
                        st.session_state.metrics = metrics
                        
                        # ì¶”ì²œ ìƒì„±
                        recommendations = recommend_environments_dynamic(
                            artifacts,
                            df,
                            st.session_state.height_target,
                            st.session_state.health_target,
                            healthy_label,
                            top_k,
                        )
                        st.session_state.recommendations = recommendations
                        
                        st.success("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                        st.balloons()
                        
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.exception(e)

            # í•™ìŠµëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë©”íŠ¸ë¦­ í‘œì‹œ
            if st.session_state.metrics:
                st.markdown("### ğŸ“Š ëª¨ë¸ í‰ê°€ ì§€í‘œ")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(
                        "ë†’ì´ MAE",
                        f"{st.session_state.metrics['height_mae']:.3f}",
                    )
                with col2:
                    st.metric(
                        "ë†’ì´ RMSE",
                        f"{st.session_state.metrics['height_rmse']:.3f}",
                    )
                with col3:
                    st.metric(
                        "ê±´ê°• ìƒíƒœ F1",
                        f"{st.session_state.metrics['health_f1']:.3f}",
                    )
                
                st.markdown("#### ë¶„ë¥˜ ë¦¬í¬íŠ¸")
                st.text(st.session_state.metrics["health_classification_report"])

    with tab4:
        st.subheader("ìµœì  í™˜ê²½ ì¶”ì²œ ê²°ê³¼")
        
        if st.session_state.recommendations is None or st.session_state.recommendations.empty:
            st.info("ğŸ‘ˆ 'ëª¨ë¸ í•™ìŠµ' íƒ­ì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        else:
            recommendations = st.session_state.recommendations
            
            st.markdown(f"### ìƒìœ„ {len(recommendations)}ê°œ ì¶”ì²œ í™˜ê²½")
            st.dataframe(recommendations, use_container_width=True)
            
            # ì‹œê°í™”
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ë†’ì´ vs ê±´ê°• í™•ë¥ ")
                st.scatter_chart(
                    recommendations,
                    x="ì˜ˆìƒ ë†’ì´",
                    y="ê±´ê°• í™•ë¥ ",
                    size="score",
                    color="score",
                )
            
            with col2:
                st.markdown("#### ì˜ˆìƒ ë†’ì´ ë¹„êµ")
                st.bar_chart(
                    recommendations.set_index(
                        recommendations.index.map(lambda x: f"í™˜ê²½ {x+1}")
                    )["ì˜ˆìƒ ë†’ì´"]
                )
            
            # ìƒì„¸ ì •ë³´
            st.markdown("#### ìƒì„¸ í™˜ê²½ ë³€ìˆ˜")
            for idx, row in recommendations.iterrows():
                with st.expander(f"í™˜ê²½ {idx+1} (ì ìˆ˜: {row['score']:.2f})"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì˜ˆìƒ ë†’ì´ (cm)", f"{row['ì˜ˆìƒ ë†’ì´']:.2f}")
                    with col2:
                        st.metric("ê±´ê°• í™•ë¥ ", f"{row['ê±´ê°• í™•ë¥ ']:.3f}")
                    with col3:
                        st.metric("ì¢…í•© ì ìˆ˜", f"{row['score']:.2f}")
                    
                    st.json(row[st.session_state.selected_features].to_dict())
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = recommendations.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“¥ ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="rock_pine_recommendations.csv",
                mime="text/csv",
            )

